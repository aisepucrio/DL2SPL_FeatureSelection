{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da8b1ff-d256-4adf-9dba-b32dea2ea20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning.pytorch as L  # Novo estilo unificado\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8152004d-2c5d-42e1-b875-9197e66b3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/jupyter-jphuser2\"  # ajuste aqui\n",
    "output_plot_dir = os.path.join(base_path, \"plots_full\")\n",
    "os.makedirs(output_plot_dir, exist_ok=True)\n",
    "best_checkpoints = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd829c23-1ed5-4f85-a3d7-f5ff95439bd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/home/jupyter-jphuser2/logs_and_plots.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m feature_selection \u001b[38;5;241m=\u001b[39m folder\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, folder)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, config)):\n\u001b[1;32m      8\u001b[0m         best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/home/jupyter-jphuser2/logs_and_plots.zip'"
     ]
    }
   ],
   "source": [
    "# Coleta melhores checkpoints por configuração\n",
    "for folder in os.listdir(base_path):\n",
    "    if folder.startswith(\"logs_\"):\n",
    "        feature_selection = folder.replace(\"logs_\", \"\")\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        for config in os.listdir(folder_path):\n",
    "            if config.startswith(\"checkpoints_\") and os.path.isdir(os.path.join(folder_path, config)):\n",
    "                best_loss = float('inf')\n",
    "                best_ckpt = None\n",
    "                for file in os.listdir(os.path.join(folder_path, config)):\n",
    "                    match = re.search(r\"val_loss=(\\d+(?:\\.\\d+)?)\", file)\n",
    "                    if match:\n",
    "                        val_loss = float(match.group(1))\n",
    "                        if val_loss < best_loss:\n",
    "                            best_loss = val_loss\n",
    "                            best_ckpt = os.path.join(folder_path, config, file)\n",
    "                if best_ckpt:\n",
    "                    parts = config.replace(\"checkpoints_\", \"\").split(\"_\")\n",
    "                    best_checkpoints.append({\n",
    "                        'feature_selection': feature_selection,\n",
    "                        'optimizer': parts[0],\n",
    "                        'loss': parts[1],\n",
    "                        'activation': '_'.join(parts[2:]),\n",
    "                        'val_loss': best_loss,\n",
    "                        'checkpoint_path': best_ckpt\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee2caec-a9bc-476a-abb7-043ac0c9a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do modelo Lightning (execute antes de gerar plots)\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning.pytorch as L\n",
    "\n",
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, num_features, activation=\"ReLU\", optimizer_name=\"Adam\", loss_name=\"MSE\", dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.activation = activation\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.loss_name = loss_name\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        loss = self.get_loss_function()(z, y.unsqueeze(1))\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        loss = self.get_loss_function()(z, y.unsqueeze(1))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.get_optimizer()\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        optimizers = {\n",
    "            \"Adam\": torch.optim.Adam(self.parameters(), lr=0.001),\n",
    "            \"AdamW\": torch.optim.AdamW(self.parameters(), lr=0.001),\n",
    "        }\n",
    "        return optimizers[self.optimizer_name]\n",
    "\n",
    "    def get_loss_function(self):\n",
    "        loss_functions = {\n",
    "            \"MSE\": nn.MSELoss(),\n",
    "            \"SmoothL1Loss\": nn.SmoothL1Loss(),\n",
    "            \"MAE\": nn.L1Loss()\n",
    "        }\n",
    "        return loss_functions[self.loss_name]\n",
    "\n",
    "    def get_activation(self):\n",
    "        activations = {\n",
    "            \"ReLU\": nn.ReLU(),\n",
    "            \"PReLU\": nn.PReLU(),\n",
    "            \"ELU\": nn.ELU(),\n",
    "            \"LeakyReLU\": nn.LeakyReLU()\n",
    "        }\n",
    "        return activations[self.activation]\n",
    "\n",
    "    def build_model(self):\n",
    "        hidden_size = self.num_features // 2\n",
    "        hidden_size2 = hidden_size // 2\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.num_features, hidden_size),\n",
    "            self.get_activation(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size2),\n",
    "            self.get_activation(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size2, 1)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add-test-datasets",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m _, X_test, _, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X, y; gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 70\u001b[0m X_test_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m y_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_test\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_test, y_test; gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Cálculo de MAPE para cada modelo\n",
    "\n",
    "# %% [code]\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configurações gerais\n",
    "parquet_file    = 'data (2).parquet'\n",
    "target_column   = 'perf'\n",
    "output_mape_csv = 'mape_summary.csv'\n",
    "output_plot_dir = 'plots'\n",
    "device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# %% [code]\n",
    "# Funções auxiliares\n",
    "def json_to_dataframe(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        dados = json.load(f)\n",
    "    return pd.DataFrame(list(dados.values()), columns=['feature'])\n",
    "\n",
    "def select_top_features(df_imp, pct):\n",
    "    df_sorted = df_imp.sort_values(by='importance', ascending=False)\n",
    "    top_n = int(len(df_sorted) * pct)\n",
    "    return df_sorted['feature'].iloc[:top_n].tolist()\n",
    "\n",
    "# Carrega apenas uma vez todos os dataframes de importâncias\n",
    "importance_data = {\n",
    "    'DecisionTree':     pd.read_csv('feature_importances_DecisionTree.csv'),\n",
    "    'RandomForest':     pd.read_csv('feature_importances_RandomForest.csv'),\n",
    "    'GradientBoosting': pd.read_csv('feature_importances_GradientBoosting.csv'),\n",
    "    'XGBoost':          pd.read_csv('feature_importances_XGBoost.csv'),\n",
    "    'Word2Vec':         json_to_dataframe('data_features_w2v.json')\n",
    "}\n",
    "\n",
    "# %% [code]\n",
    "# Loop principal: gera predições, calcula MAPE e opcionalmente salva um scatter plot\n",
    "mape_records = []\n",
    "\n",
    "for ckpt in best_checkpoints:\n",
    "    # --- Seleção de colunas ---\n",
    "    fs = ckpt['feature_selection'].split('_')\n",
    "    algo, pct_label = fs[0], fs[1]\n",
    "    if algo == 'allFeatures':\n",
    "        cols = None\n",
    "    else:\n",
    "        pct = int(pct_label.replace('pct','')) / 100\n",
    "        df_imp = importance_data[algo]\n",
    "        if algo == 'Word2Vec':\n",
    "            selected = df_imp['feature'].tolist()[:int(len(df_imp)*pct)]\n",
    "        else:\n",
    "            selected = select_top_features(df_imp, pct)\n",
    "        cols = selected + [target_column]\n",
    "\n",
    "    # --- Carrega apenas colunas necessárias e divide em treino/teste ---\n",
    "    df = pd.read_parquet(parquet_file, columns=cols)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    del df; gc.collect()\n",
    "\n",
    "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    del X, y; gc.collect()\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "    del X_test, y_test; gc.collect()\n",
    "\n",
    "    # --- Carrega o modelo e faz predição ---\n",
    "    model = LightningModel.load_from_checkpoint(\n",
    "        ckpt['checkpoint_path'],\n",
    "        num_features=X_test_tensor.shape[1],\n",
    "        activation=ckpt['activation'],\n",
    "        optimizer_name=ckpt['optimizer'],\n",
    "        loss_name=ckpt['loss']\n",
    "    ).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_tensor).cpu().squeeze().numpy()\n",
    "    y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "    # --- Cálculo do MAPE ---\n",
    "    eps = 1e-8\n",
    "    mape = np.mean(np.abs((y_true - preds) / (y_true + eps))) * 100\n",
    "\n",
    "    # Armazena o resultado\n",
    "    mape_records.append({\n",
    "        \"Feature_Selection\":   ckpt['feature_selection'],\n",
    "        \"Optimizer\":           ckpt['optimizer'],\n",
    "        \"Loss_Function\":       ckpt['loss'],\n",
    "        \"Activation_Function\": ckpt['activation'],\n",
    "        \"MAPE(%)\":             mape\n",
    "    })\n",
    "\n",
    "    # (Opcional) salva scatter real vs predito\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test_tensor.cpu().numpy(), label='Valores Reais')\n",
    "    plt.plot(preds[:100], linestyle='dashed', label='Predições')\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel('Perf')\n",
    "    plt.title(f\"{ckpt['feature_selection']} | {ckpt['optimizer']}_{ckpt['loss']}_{ckpt['activation']}\")\n",
    "    plt.legend()\n",
    "\n",
    "    # salva e libera\n",
    "    fname = f\"{ckpt['feature_selection']}_{ckpt['optimizer']}_{ckpt['loss']}_{ckpt['activation']}.png\"\n",
    "    plt.savefig(os.path.join(output_plot_dir, fname))\n",
    "    plt.close()\n",
    "\n",
    "    del X_test_tensor, y_test_tensor, preds, model\n",
    "    gc.collect()\n",
    "\n",
    "# %% [code]\n",
    "# Salva o summary de MAPE em CSV\n",
    "mape_df = pd.DataFrame(mape_records)\n",
    "mape_df.to_csv(output_mape_csv, index=False)\n",
    "print(f\"Resumo de MAPE salvo em: {output_mape_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efda66-437f-42fe-987e-23df2289309f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
