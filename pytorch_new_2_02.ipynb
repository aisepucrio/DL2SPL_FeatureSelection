{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "init-logs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0195c9d-5629-4616-9e06-07de50ca0557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:491\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    480\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_properties\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "x = torch.randn(2, 2).cuda()\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nvidia-smi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 24 02:55:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:00:09.0 Off |                  N/A |\n",
      "| 37%   35C    P8             30W /  370W |      15MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1305      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Opcionalmente, podemos mostrar informações da GPU\n",
    "# print(\"get_ipython().system('nvidia-smi') executado para demonstrar a GPU em uso.\")\n",
    "get_ipython().system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import lightning.pytorch as L  # Novo estilo unificado\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# Plotagem\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Geral\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"lightning.pytorch.callbacks.model_checkpoint\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "set_precision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta a precisão de multiplicações de matriz do PyTorch\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43005f3a-664f-45cc-80bd-fd1ccc646cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_to_dataframe(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        dados_json = json.load(f)\n",
    "    \n",
    "    features = list(dados_json.values())\n",
    "    df = pd.DataFrame(features, columns=[\"feature\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "select_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para selecionar as top features (usando top_percentage)\n",
    "def select_top_features(df_importance: pd.DataFrame, top_percentage=0.7):\n",
    "    df_sorted = df_importance.sort_values(by='importance', ascending=False)\n",
    "    top_n = int(len(df_sorted) * top_percentage)\n",
    "    return df_sorted.head(top_n)['feature'].tolist()\n",
    "\n",
    "def select_top_features_word2vec(df_importance: pd.DataFrame, top_percentage=0.7):\n",
    "    top_n = int(len(df_importance) * top_percentage)\n",
    "    return df_importance.head(top_n)['feature'].tolist()\n",
    "\n",
    "# Carrega CSVs com importâncias\n",
    "decision_tree = pd.read_csv('feature_importances_DecisionTree.csv')\n",
    "random_forest = pd.read_csv('feature_importances_RandomForest.csv')\n",
    "gradient_boosting = pd.read_csv('feature_importances_GradientBoosting.csv')\n",
    "xgboost = pd.read_csv('feature_importances_XGBoost.csv')\n",
    "word2vec = json_to_dataframe('data_features_w2v.json')\n",
    "\n",
    "# Dicionário contendo as features mais importantes de cada algoritmo\n",
    "top_features_dict = {\n",
    "    'DecisionTree': select_top_features(decision_tree, top_percentage=0.7),\n",
    "    'RandomForest': select_top_features(random_forest, top_percentage=0.7),\n",
    "    'GradientBoosting': select_top_features(gradient_boosting, top_percentage=0.7),\n",
    "    'XGBoost': select_top_features(xgboost, top_percentage=0.7),\n",
    "    'Word2Vec': select_top_features_word2vec(word2vec, top_percentage=0.7)\n",
    "}\n",
    "\n",
    "# Também definimos:\n",
    "parquet_file = \"data (2).parquet\"\n",
    "target_column = \"perf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "check_gpu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Verifica se há GPU disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "custom_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset customizado (igual ao primeiro notebook)\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lightning_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, num_features, activation=\"ReLU\", optimizer_name=\"Adam\", loss_name=\"MSE\", dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.activation = activation\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.loss_name = loss_name\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        loss = self.get_loss_function()(z, y.unsqueeze(1))\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        loss = self.get_loss_function()(z, y.unsqueeze(1))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.get_optimizer()\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        optimizers = {\n",
    "            \"Adam\": torch.optim.Adam(self.parameters(), lr=0.001),\n",
    "            \"AdamW\": torch.optim.AdamW(self.parameters(), lr=0.001),\n",
    "        }\n",
    "        return optimizers[self.optimizer_name]\n",
    "\n",
    "    def get_loss_function(self):\n",
    "        loss_functions = {\n",
    "            \"MSE\": nn.MSELoss(),\n",
    "            \"SmoothL1Loss\": nn.SmoothL1Loss(),\n",
    "            \"MAE\": nn.L1Loss()\n",
    "        }\n",
    "        return loss_functions[self.loss_name]\n",
    "\n",
    "    def get_activation(self):\n",
    "        activations = {\n",
    "            \"ReLU\": nn.ReLU(),\n",
    "            \"PReLU\": nn.PReLU(),\n",
    "            \"ELU\": nn.ELU(),\n",
    "            \"LeakyReLU\": nn.LeakyReLU()\n",
    "        }\n",
    "        return activations[self.activation]\n",
    "\n",
    "    def build_model(self):\n",
    "        hidden_size = self.num_features // 2\n",
    "        hidden_size2 = hidden_size // 2\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.num_features, hidden_size),\n",
    "            self.get_activation(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size2),\n",
    "            self.get_activation(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size2, 1)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "custom_early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback de Early Stopping customizado (do primeiro notebook)\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "class CustomEarlyStopping(Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        monitor=\"val_loss\",\n",
    "        patience_base=10,\n",
    "        min_delta_factor=0.1,\n",
    "        max_patience=20,\n",
    "        window=5,\n",
    "        mode=\"min\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.patience_base = patience_base\n",
    "        self.min_delta_factor = min_delta_factor\n",
    "        self.max_patience = max_patience\n",
    "        self.window = window\n",
    "        self.mode = mode\n",
    "\n",
    "        self.best_score = float(\"inf\") if mode == \"min\" else float(\"-inf\")\n",
    "        self.best_state_dict = None\n",
    "        self.wait = 0\n",
    "        self.loss_history = []\n",
    "\n",
    "        self.start_time = None\n",
    "        self.total_time = 0\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if self.start_time is not None:\n",
    "            self.total_time = time.time() - self.start_time\n",
    "            trainer.logger.log_metrics({\"train_time\": int(self.total_time)}, step=trainer.current_epoch)\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        current_score = trainer.callback_metrics.get(self.monitor)\n",
    "        if current_score is None:\n",
    "            return\n",
    "        current_score = float(current_score)\n",
    "        self.loss_history.append(current_score)\n",
    "\n",
    "        if len(self.loss_history) > self.window:\n",
    "            self.loss_history.pop(0)\n",
    "\n",
    "        if len(self.loss_history) >= self.window:\n",
    "            std_dev = np.std(self.loss_history)\n",
    "            min_delta = self.min_delta_factor * std_dev\n",
    "            patience_dynamic = (min(self.patience_base + int(std_dev / min_delta), self.max_patience)\n",
    "                if min_delta != 0 else self.patience_base\n",
    "            )\n",
    "        else:\n",
    "            min_delta = 1e-3\n",
    "            patience_dynamic = self.patience_base\n",
    "\n",
    "        improved = False\n",
    "        if self.mode == \"min\":\n",
    "            if (self.best_score - current_score) > min_delta:\n",
    "                improved = True\n",
    "        else:\n",
    "            if (current_score - self.best_score) > min_delta:\n",
    "                improved = True\n",
    "\n",
    "        if improved:\n",
    "            self.best_score = current_score\n",
    "            self.best_state_dict = copy.deepcopy(pl_module.state_dict())\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= patience_dynamic:\n",
    "                print(f\"[CustomEarlyStopping] Parando no epoch={trainer.current_epoch}. Tempo total: {int(self.total_time)} seg.\")\n",
    "                if self.best_state_dict is not None:\n",
    "                    pl_module.load_state_dict(self.best_state_dict)\n",
    "                trainer.should_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "train_model_tune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar um modelo dado uma combinação de hiperparâmetros (sem Ray, igual ao primeiro notebook)\n",
    "def train_model_tune(config, num_features, train_dataset, test_dataset, batch_size=256, max_epochs=50, num_workers=8, logs_dir=\"logs\"):\n",
    "    config_id = f\"{config['optimizer']}_{config['loss_function']}_{config['activation']}\"\n",
    "    csv_logger = CSVLogger(save_dir=logs_dir, name=config_id)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    model = LightningModel(\n",
    "        num_features=num_features,\n",
    "        activation=config[\"activation\"],\n",
    "        optimizer_name=config[\"optimizer\"],\n",
    "        loss_name=config[\"loss_function\"],\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    early_stop_callback = CustomEarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience_base=10,\n",
    "        min_delta_factor=0.4,\n",
    "        max_patience=20,\n",
    "        window=5,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=os.path.join(logs_dir, \"checkpoints_\" + config_id),\n",
    "        filename=\"epoch-{epoch:02d}-val_loss-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        verbose=False,\n",
    "        save_weights_only=True,\n",
    "        every_n_epochs=1,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        callbacks=[early_stop_callback, checkpoint_callback],\n",
    "        logger=csv_logger,\n",
    "        enable_progress_bar=True\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "grid_search",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "def run_grid_search(num_features, train_dataset, test_dataset, param_grid,\n",
    "                    algo_name=\"FeatureSelection\", batch_size=256, max_epochs=50, num_workers=8):\n",
    "    results = {}\n",
    "    keys = list(param_grid.keys())\n",
    "    values = [param_grid[k] for k in keys]\n",
    "\n",
    "    for config_values in itertools.product(*values):\n",
    "        config = dict(zip(keys, config_values))\n",
    "\n",
    "        # Extrai e formata o dropout para compor o nome da pasta\n",
    "        drop = str(config[\"dropout_rate\"]).replace(\".\", \"\")\n",
    "        logs_dir = f\"logs_{algo_name}_{drop}\"\n",
    "\n",
    "        # Garante que a pasta exista\n",
    "        os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "        print(\"\\nTreinando com a configuração:\", config, \"| Algoritmo:\", algo_name)\n",
    "\n",
    "        train_model_tune(\n",
    "            config=config,\n",
    "            num_features=num_features,\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=max_epochs,\n",
    "            num_workers=num_workers,\n",
    "            logs_dir=logs_dir\n",
    "        )\n",
    "        results[str(config)] = \"Métricas salvas no CSVLogger em \" + logs_dir\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grid_search_run",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iniciando experimento para XGBoost com 50pct das features ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando com a configuração: {'optimizer': 'Adam', 'loss_function': 'MAE', 'activation': 'ELU', 'dropout_rate': 0.3} | Algoritmo: XGBoost_50pct\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m num_features \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Roda o grid search para esse algoritmo + percentual\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_grid_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43malgo_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpct_label\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultados do grid search para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpct_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features):\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mrun_grid_search\u001b[0;34m(num_features, train_dataset, test_dataset, param_grid, algo_name, batch_size, max_epochs, num_workers)\u001b[0m\n\u001b[1;32m     18\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(logs_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTreinando com a configuração:\u001b[39m\u001b[38;5;124m\"\u001b[39m, config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m| Algoritmo:\u001b[39m\u001b[38;5;124m\"\u001b[39m, algo_name)\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mtrain_model_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogs_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs_dir\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     results[\u001b[38;5;28mstr\u001b[39m(config)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMétricas salvas no CSVLogger em \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m logs_dir\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m, in \u001b[0;36mtrain_model_tune\u001b[0;34m(config, num_features, train_dataset, test_dataset, batch_size, max_epochs, num_workers, logs_dir)\u001b[0m\n\u001b[1;32m     37\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     38\u001b[0m     dirpath\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(logs_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m config_id),\n\u001b[1;32m     39\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch-\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-val_loss-\u001b[39m\u001b[38;5;132;01m{val_loss:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     49\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m     50\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     enable_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     55\u001b[0m )\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:938\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;66;03m# SET UP THE TRAINER\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    937\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: setting up strategy environment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setup_profiler()\n\u001b[1;32m    941\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:129\u001b[0m, in \u001b[0;36mStrategy.setup_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Setup any processes or distributed connections.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mThis is called before the LightningModule/DataModule setup hook which allows the user to access the accelerator\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03menvironment before setup is complete.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/pytorch/accelerators/cuda.py:46\u001b[0m, in \u001b[0;36mCUDAAccelerator.setup_device\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice should be GPU, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43m_check_cuda_matmul_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/fabric/accelerators/cuda.py:161\u001b[0m, in \u001b[0;36m_check_cuda_matmul_precision\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# show the warning only ever once\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_cuda_matmul_precision\u001b[39m(device: torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_is_ampere_or_later\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# check that the user hasn't changed the precision already, this works for both `allow_tf32 = True` and\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# `set_float32_matmul_precision`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightning/fabric/accelerators/cuda.py:155\u001b[0m, in \u001b[0;36m_is_ampere_or_later\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_is_ampere_or_later\u001b[39m(device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     major, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_capability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m major \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:507\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_capability\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     prop \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_properties\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.12/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "# RODAMOS A VARIAÇÃO DE PORCENTAGENS DE FEATURES SELECIONADAS PARA CADA ALGORITMO\n",
    "####################################################################################\n",
    "\n",
    "param_grid = {\n",
    "    \"optimizer\": [\"Adam\", \"AdamW\"],\n",
    "    \"loss_function\": [\"MAE\", \"MSE\", \"SmoothL1Loss\"],\n",
    "    \"activation\": [\"ELU\", \"PReLU\", \"ReLU\", \"LeakyReLU\"],\n",
    "    \"dropout_rate\": [0.3]\n",
    "}\n",
    "\n",
    "# Percentuais de features que serão testados\n",
    "feature_percentages = [0.5]\n",
    "\n",
    "# Carrega CSVs de importância apenas uma vez\n",
    "importance_data = {\n",
    "    # 'DecisionTree': pd.read_csv('feature_importances_DecisionTree.csv'),\n",
    "    # 'RandomForest': pd.read_csv('feature_importances_RandomForest.csv'),\n",
    "    # 'GradientBoosting': pd.read_csv('feature_importances_GradientBoosting.csv'),\n",
    "    'XGBoost': pd.read_csv('feature_importances_XGBoost.csv'),\n",
    "    # 'Word2Vec': json_to_dataframe('data_features_w2v.json')\n",
    "}\n",
    "\n",
    "for pct in feature_percentages:\n",
    "    pct_label = f\"{int(pct * 100)}pct\"\n",
    "    \n",
    "    for algo_name, df_importance in importance_data.items():\n",
    "        print(f\"=== Iniciando experimento para {algo_name} com {pct_label} das features ===\")\n",
    "        \n",
    "        # Aplica a função para selecionar features com base no percentual\n",
    "        if algo_name == 'Word2Vec':\n",
    "            selected_features = select_top_features_word2vec(df_importance, top_percentage=pct)\n",
    "        else:\n",
    "            selected_features = select_top_features(df_importance, top_percentage=pct)\n",
    "        columns_needed = selected_features + [target_column]\n",
    "\n",
    "        # Carrega os dados com as colunas necessárias\n",
    "        df = pd.read_parquet(parquet_file, columns=columns_needed)\n",
    "        df = df.astype('float32')\n",
    "\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column]\n",
    "        del df\n",
    "        gc.collect()\n",
    "        \n",
    "        # Divide em treino e teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        del X, y\n",
    "        gc.collect()\n",
    "        \n",
    "        # Converte para tensores\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "        del X_train, X_test, y_train, y_test\n",
    "        gc.collect()\n",
    "\n",
    "        train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset  = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "        num_features = train_dataset.features.shape[1]\n",
    "\n",
    "        # Roda o grid search para esse algoritmo + percentual\n",
    "        results = run_grid_search(\n",
    "            num_features=num_features,\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            param_grid=param_grid,\n",
    "            algo_name=f\"{algo_name}_{pct_label}\",\n",
    "            batch_size=1024,\n",
    "            max_epochs=300,\n",
    "            num_workers=8\n",
    "        )\n",
    "\n",
    "        print(f\"Resultados do grid search para {algo_name} ({pct_label} features):\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_load_plot_example_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CÉLULA FINAL: Carregar um modelo treinado a partir de um checkpoint e plotar os resultados ---\n",
    "\n",
    "# Atualiza a função plot_results para mover os dados para o mesmo dispositivo do modelo\n",
    "def plot_results(model, dataset, batch_size=1024):\n",
    "    model.eval()\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            # Move x para o mesmo dispositivo do modelo\n",
    "            x = x.to(next(model.parameters()).device)\n",
    "            preds = model(x).squeeze()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(y.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_true = np.array(all_true)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(all_true, all_preds, alpha=0.5)\n",
    "    plt.xlabel(\"Valores Reais\")\n",
    "    plt.ylabel(\"Predições\")\n",
    "    plt.title(\"Comparação: Predições vs Valores Reais\")\n",
    "    \n",
    "    min_val = min(all_true.min(), all_preds.min())\n",
    "    max_val = max(all_true.max(), all_preds.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    plt.show()\n",
    "\n",
    "# Supondo que o test_dataset já esteja definido e preparado:\n",
    "num_features = test_dataset.features.shape[1]\n",
    "\n",
    "# Defina o caminho para o checkpoint do modelo treinado\n",
    "best_model_path = \"logs_DecisionTree/checkpoints_Adam_MAE_ELU/epoch-epoch=299-val_loss-val_loss=8850943.00.ckpt\"\n",
    "\n",
    "# Carrega o modelo treinado a partir do checkpoint, passando os mesmos parâmetros usados no treinamento\n",
    "loaded_model = LightningModel.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    num_features=num_features,\n",
    "    activation=\"ELU\",\n",
    "    optimizer_name=\"Adam\",\n",
    "    loss_name=\"MAE\"\n",
    ")\n",
    "\n",
    "# Move o modelo para o dispositivo (GPU ou CPU) conforme definido na variável 'device'\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Plota os resultados utilizando o test_dataset\n",
    "plot_results(loaded_model, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca6d82-e354-48af-8c5b-7f4a44a2e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera as predições usando o modelo carregado, movendo o tensor de entrada para o mesmo dispositivo do modelo\n",
    "pred = loaded_model(X_test_tensor.to(device)).cpu().detach().numpy()\n",
    "\n",
    "# Converte os valores reais para numpy (usando apenas os primeiros 100 elementos)\n",
    "y_true = y_test_tensor.cpu().detach().numpy()[:100]\n",
    "\n",
    "# Plota os valores reais e as predições\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_true, color='b', label='Valores Reais')\n",
    "plt.plot(pred[:100], color='r', linestyle='dashed', label='Predições')\n",
    "plt.title(\"Comparação: Valores Reais vs Predições (primeiros 100)\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb4156-ada1-4efc-9855-64f41b954f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
